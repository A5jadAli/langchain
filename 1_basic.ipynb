{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm_claude = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_gpt = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_claude.invoke(\"What is LangChain?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt.invoke(\"What is LangChain?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You explain things to the people like they are five years old.\"\"\"\n",
    "user_prompt = f\"What is LangChain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import textwrap\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=user_prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_claude.invoke(messages)\n",
    "answer = textwrap.fill(response.content, width=100)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant who explain blockchain and metaverse concepts. Given an input topic {topic},\n",
    "explain it to the user like they are five years old.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the chain using pipe \"|\" operator\n",
    "chain = prompt | llm_claude\n",
    "\n",
    "# invoke the chain\n",
    "response = chain.invoke(topic=\"What is Metaverse?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --quiet youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\"https://youtube.com/shorts/7eT12YMA8oE?si=E3LBCPNDjvn1IYkA\", \n",
    "                                        add_video_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using built-in chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant who explain blockchain and metaverse concepts. Given the following context {context},\n",
    "summarize it like the users are completely non-technical.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "chain = create_stuff_documents_chain(prompt, llm_claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LECL & Runnables\n",
    "\n",
    "- LECL simplifies building complex chains using basic componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant who explain blockchain and metaverse concepts. Given the following context {context},\n",
    "summarize it like the users are completely non-technical.\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(prompt_template)\n",
    "summarize_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = summarize_prompt | llm_claude | output_parser\n",
    "chain.invoke({\"context\":\"What is Metaverse?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the type of the chain\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnable Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "summarize_chain = summarize_prompt | llm_claude | output_parser\n",
    "\n",
    "# define a custom lambda function and wrap it in runnablelambda\n",
    "length_lambda = RunnableLambda(lambda summary: f\"Length of Summary: {len(summary)} characters.\")\n",
    "\n",
    "lambda_chain = summarize_chain | length_lambda\n",
    "\n",
    "lambda_chain.invoke({\"context\":\"What is Web 3.0?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lambda_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use functions in chains without RunnableLambda\n",
    "chain_with_function = summarize_chain | (lambda summary: f\"Length of Summary: {len(summary)} characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(chain_with_function.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassthrough as Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "placeholder_chain = summarize_chain | passthrough | length_lambda\n",
    "\n",
    "result = placeholder_chain.invoke({\"context\": \"What is LangChain?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(placeholder_chain.steps[-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassthrough can also be used for assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_summary_lambda = RunnableLambda(lambda summary: {\"summary\": summary})\n",
    "assign_passthrough = RunnablePassthrough.assign(length=lambda x: len(x[\"summary\"]))\n",
    "\n",
    "summarize_chain = summarize_prompt | llm_claude | output_parser | wrap_summary_lambda\n",
    "assign_chain = summarize_chain | assign_passthrough\n",
    "\n",
    "result = assign_chain.invoke({\"context\": \"What is LangChain?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(assign_chain.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
    "\n",
    "parallel_runnable = RunnableParallel(\n",
    "    summary=lambda x: x,  # Passes the summary as is\n",
    "    length=lambda x: len(x)  # Calculates the length of the summary\n",
    ")\n",
    "\n",
    "parallel_chain = summarize_chain | parallel_runnable\n",
    "\n",
    "result = parallel_chain.invoke({\"context\": \"What is LangChain?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(parallel_chain.steps[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitters & Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --quiet redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\"https://youtube.com/shorts/7eT12YMA8oE?si=E3LBCPNDjvn1IYkA\", \n",
    "                                        add_video_info=False)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function = len,\n",
    "    is_separator_regex=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup [Redis](https://app.redislabs.com/#/) database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_URL = \"redis://default:pUAdNGT2ewgXQKHzEu30pGNbHViOlPG1@redis-15765.c281.us-east-1-2.ec2.redns.redis-cloud.com:15765\"\n",
    "REDIS_HOST = \"redis-15765.c281.us-east-1-2.ec2.redns.redis-cloud.com\"\n",
    "REDIS_PASSWORD = \"pUAdNGT2ewgXQKHzEu30pGNbHViOlPG1\"\n",
    "REDIS_PORT = \"15765\"\n",
    "\n",
    "import redis\n",
    "\n",
    "r = redis.Redis(\n",
    "  host=REDIS_HOST,\n",
    "  port=REDIS_PORT,\n",
    "  password=REDIS_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flush database to make sure it's empty\n",
    "r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.redis import Redis\n",
    "\n",
    "rds = Redis.from_documents(\n",
    "    docs_split,\n",
    "    embeddings,\n",
    "    redis_url = REDIS_URL,\n",
    "    index_name = \"youtube\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = rds.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"IELTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": (lambda x: x[\"question\"]) | retriever,\n",
    "     \"question\": (lambda x: x[\"question\"])}\n",
    "    | prompt\n",
    "    | llm_claude\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke({\"question\": \"What can you do with LLama 3?\"})\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
